from fastapi import FastAPI, UploadFile, File, HTTPException
from contextlib import asynccontextmanager
from io import BytesIO
from PIL import Image

# ë¼ìš°í„° ì„í¬íŠ¸
from heritage.router import router as heritage_router
from ai.router import router as ai_router
from image.router import router as image_router

# ê³µí†µ ì„¤ì •
from common.config import settings
from common.middleware import setup_middleware

# AI ëª¨ë¸ ë¡œë”
from ai.loader import load_ai_model

# Damage Inference ëª¨ë“ˆ (ë…¸íŠ¸ë¶ ë¡œì§ ê¸°ë°˜)
try:
    import damage_inference
    DAMAGE_INFERENCE_AVAILABLE = True
except Exception as e:
    print(f"[Main] âš ï¸  damage_inference ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    DAMAGE_INFERENCE_AVAILABLE = False


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬
    - startup: AI ëª¨ë¸ ë¡œë“œ
    - shutdown: ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    """
    # Startup
    print("=" * 60)
    print(f"ğŸš€ {settings.APP_TITLE} v{settings.APP_VERSION} ì‹œì‘")
    print("=" * 60)

    # AI ëª¨ë¸ ë¡œë“œ
    print("\n[Startup] AI ëª¨ë¸ ë¡œë”© ì¤‘...")
    loaded = load_ai_model()
    if loaded:
        print("[Startup] âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    else:
        print("[Startup] âš ï¸  AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (AI ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

    print("\n[Startup] ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"[Startup] ì„œë²„ ì£¼ì†Œ: http://{settings.HOST}:{settings.PORT}")
    print(f"[Startup] API ë¬¸ì„œ: http://{settings.HOST}:{settings.PORT}/docs")
    print("=" * 60 + "\n")

    yield

    # Shutdown
    print("\n[Shutdown] ì„œë²„ ì¢…ë£Œ ì¤‘...")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=settings.APP_TITLE,
    version=settings.APP_VERSION,
    description=settings.APP_DESCRIPTION,
    lifespan=lifespan,
)

# ë¯¸ë“¤ì›¨ì–´ ì„¤ì • (CORS ë“±)
setup_middleware(app)

# ë¼ìš°í„° ë“±ë¡
app.include_router(heritage_router, prefix="/heritage", tags=["Heritage"])
app.include_router(ai_router, prefix="/ai", tags=["AI Detection"])
app.include_router(image_router, prefix="/image", tags=["Image Proxy"])


# ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/", tags=["Root"])
async def root():
    """API ë£¨íŠ¸ - ì„œë²„ ì •ë³´ ë°˜í™˜"""
    return {
        "service": settings.APP_TITLE,
        "version": settings.APP_VERSION,
        "status": "running",
        "docs": "/docs",
        "endpoints": {
            "heritage_list": "/heritage/list",
            "heritage_detail": "/heritage/detail",
            "ai_status": "/ai/model/status",
            "ai_infer": "/ai/damage/infer",
            "image_proxy": "/image/proxy",
        }
    }


@app.get("/health", tags=["Health"])
async def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "ok", "service": settings.APP_TITLE}


@app.post("/ai/damage/infer")
async def ai_damage_infer(image: UploadFile = File(...)):
    """
    Run the hanok damage detection model on the uploaded image and
    return detected damage bounding boxes.
    
    Returns:
        {
            "detections": [
                {
                    "label_id": int,      # 0-3
                    "label": str,         # "ê°ˆë¨", "ê· ì—´", "ë¶€í›„", "ì••ê´´/í„°ì§"
                    "score": float,       # 0.0-1.0
                    "x": float,           # normalized center x [0, 1]
                    "y": float,           # normalized center y [0, 1]
                    "w": float,           # normalized width [0, 1]
                    "h": float            # normalized height [0, 1]
                },
                ...
            ]
        }
    """
    if not DAMAGE_INFERENCE_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Damage inference module is not available. Check server logs."
        )
    
    try:
        content = await image.read()
        pil_img = Image.open(BytesIO(content)).convert("RGB")
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid image file: {str(e)}"
        )
    
    try:
        detections = damage_inference.infer_damage(pil_img)
    except RuntimeError as e:
        raise HTTPException(
            status_code=503,
            detail=f"Model inference failed: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Unexpected error during inference: {str(e)}"
        )
    
    return {"detections": detections}


# ì„œë²„ ì§ì ‘ ì‹¤í–‰ (ê°œë°œìš©)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.RELOAD,
    )
