"""
AI ëª¨ë¸ ë¡œë”
ëª¨ë¸ ë¡œë”© ë° ìƒíƒœ ê´€ë¦¬
"""
import os
import glob
import torch
from transformers import DetaImageProcessor
from .model import CustomDeta

# ì „ì—­ ë³€ìˆ˜
model = None
processor = None
id2label = None
id2label_korean = None


def _find_model_path():
    """
    ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    1. í™˜ê²½ë³€ìˆ˜ MODEL_PATH í™•ì¸
    2. í´ë”ì¸ ê²½ìš° best ëª¨ë¸ ìë™ ì„ íƒ
    3. ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ .pt ë˜ëŠ” .pth íŒŒì¼
    """
    # í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ ê²½ë¡œ ì§€ì • ê°€ëŠ¥
    env_path = os.getenv("MODEL_PATH")
    if env_path:
        model_path = env_path
    else:
        # ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
        ai_dir = os.path.dirname(__file__)
        # .pt ë˜ëŠ” .pth íŒŒì¼ ì°¾ê¸°
        pt_files = glob.glob(os.path.join(ai_dir, "*.pt"))
        pth_files = glob.glob(os.path.join(ai_dir, "*.pth"))
        all_files = pt_files + pth_files
        
        if all_files:
            # íŒŒì¼ì´ ì—¬ëŸ¬ ê°œë©´ ê°€ì¥ ìµœê·¼ ê²ƒ ì„ íƒ
            model_path = max(all_files, key=os.path.getmtime)
        else:
            # ê¸°ë³¸ íŒŒì¼ëª… ì‹œë„
            default_pt = os.path.join(ai_dir, "hanok_damage_model.pt")
            default_pth = os.path.join(ai_dir, "hanok_damage_model.pth")
            if os.path.exists(default_pt):
                model_path = default_pt
            elif os.path.exists(default_pth):
                model_path = default_pth
            else:
                return None
    
    # í´ë”ì¸ ê²½ìš° best ëª¨ë¸ ì°¾ê¸°
    if os.path.isdir(model_path):
        return _find_best_checkpoint(model_path)
    elif os.path.isfile(model_path):
        return model_path
    else:
        return None


def _find_best_checkpoint(model_dir):
    """
    í´ë” ë‚´ì—ì„œ best_mapì´ ê°€ì¥ ë†’ì€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤
    (ë…¸íŠ¸ë¶ì˜ find_best_checkpoint í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§)
    """
    print(f"[AI] ëª¨ë¸ í´ë”ì—ì„œ ìµœì  ëª¨ë¸ ê²€ìƒ‰ ì¤‘: {model_dir}")
    
    # ëª¨ë“  .pth íŒŒì¼ ì°¾ê¸°
    checkpoint_files = glob.glob(os.path.join(model_dir, "*.pth"))
    checkpoint_files.extend(glob.glob(os.path.join(model_dir, "*.pt")))
    
    if not checkpoint_files:
        print(f"[AI] âš ï¸  {model_dir}ì— ëª¨ë¸ íŒŒì¼(.pth/.pt)ì´ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    print(f"[AI] ë°œê²¬ëœ ì²´í¬í¬ì¸íŠ¸: {len(checkpoint_files)}ê°œ")
    
    best_checkpoint_path = None
    best_map_value = -1
    
    # ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ ë¶„ì„
    for ckpt_path in sorted(checkpoint_files):
        try:
            ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)
            epoch = ckpt.get('epoch', -1)
            best_map = ckpt.get('best_map', -1)
            
            filename = os.path.basename(ckpt_path)
            print(f"[AI]   ğŸ“„ {filename} - Epoch: {epoch + 1 if epoch >= 0 else 'N/A'}, Best mAP: {best_map:.4f if best_map >= 0 else 'N/A'}")
            
            # best_mapì´ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
            if isinstance(best_map, (int, float)) and best_map > best_map_value:
                best_map_value = best_map
                best_checkpoint_path = ckpt_path
                
        except Exception as e:
            print(f"[AI]   âš ï¸  {os.path.basename(ckpt_path)}: ë¡œë“œ ì‹¤íŒ¨ - {e}")
            continue
    
    if best_checkpoint_path:
        print(f"[AI] âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ: {os.path.basename(best_checkpoint_path)} (Best mAP: {best_map_value:.4f})")
        return best_checkpoint_path
    else:
        # best_mapì´ ì—†ìœ¼ë©´ ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
        print(f"[AI] âš ï¸  best_map ì •ë³´ê°€ ì—†ì–´ ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        best_checkpoint_path = max(checkpoint_files, key=os.path.getmtime)
        print(f"[AI] âœ… ì„ íƒëœ ëª¨ë¸: {os.path.basename(best_checkpoint_path)}")
        return best_checkpoint_path


def load_ai_model():
    """AI ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
    global model, processor, id2label, id2label_korean

    try:
        # ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
        model_path = _find_model_path()
        if not model_path:
            print(f"[AI] âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print(f"[AI]    ë‹¤ìŒ ìœ„ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print(f"[AI]    1. í™˜ê²½ë³€ìˆ˜ MODEL_PATH ì„¤ì •")
            print(f"[AI]    2. {os.path.dirname(__file__)}/ ë””ë ‰í† ë¦¬ì— .pt ë˜ëŠ” .pth íŒŒì¼ ë°°ì¹˜")
            return False

        print(f"[AI] ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì¤‘: {model_path}")
        
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        if not os.path.exists(model_path):
            print(f"[AI] âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
            return False
        
        file_size = os.path.getsize(model_path)
        print(f"[AI] ëª¨ë¸ íŒŒì¼ í¬ê¸°: {file_size / (1024*1024):.2f} MB")
        
        # íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ (ZIP ì•„ì¹´ì´ë¸Œì¸ ê²½ìš°)
        if model_path.endswith(('.pth', '.pt')):
            try:
                import zipfile
                with zipfile.ZipFile(model_path, 'r') as z:
                    z.testzip()
                print(f"[AI] âœ… ZIP ì•„ì¹´ì´ë¸Œ ë¬´ê²°ì„± ê²€ì‚¬ í†µê³¼")
            except zipfile.BadZipFile:
                print(f"[AI] âš ï¸  ZIP ì•„ì¹´ì´ë¸Œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤ (ì •ìƒì¼ ìˆ˜ ìˆìŒ)")
            except Exception as e:
                print(f"[AI] âš ï¸  íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {str(e)[:100]}")
        
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ ì‹œë„
        checkpoint = None
        last_error = None
        
        # ë°©ë²• 1: ê¸°ë³¸ ë°©ë²•
        try:
            print(f"[AI] ë¡œë“œ ì‹œë„: ê¸°ë³¸ ë°©ë²• (weights_only=False)")
            checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
            print(f"[AI] âœ… ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ ë¡œë“œ ì„±ê³µ!")
        except Exception as e:
            last_error = e
            print(f"[AI] âš ï¸  ê¸°ë³¸ ë°©ë²• ì‹¤íŒ¨: {str(e)[:200]}")
            
            # ë°©ë²• 2: weights_only=True (ë³´ì•ˆ ê²½ê³  ë¬´ì‹œ)
            try:
                print(f"[AI] ë¡œë“œ ì‹œë„: weights_only=True")
                checkpoint = torch.load(model_path, map_location="cpu", weights_only=True)
                print(f"[AI] âœ… weights_only=Trueë¡œ ë¡œë“œ ì„±ê³µ!")
            except Exception as e2:
                last_error = e2
                print(f"[AI] âš ï¸  weights_only=True ì‹¤íŒ¨: {str(e2)[:200]}")
                
                # ë°©ë²• 3: íŒŒì¼ í•¸ë“¤ ì§ì ‘ ì‚¬ìš©
                try:
                    print(f"[AI] ë¡œë“œ ì‹œë„: íŒŒì¼ í•¸ë“¤ ì§ì ‘ ì‚¬ìš©")
                    with open(model_path, 'rb') as f:
                        checkpoint = torch.load(f, map_location="cpu", weights_only=False)
                    print(f"[AI] âœ… íŒŒì¼ í•¸ë“¤ë¡œ ë¡œë“œ ì„±ê³µ!")
                except Exception as e3:
                    last_error = e3
                    print(f"[AI] âš ï¸  íŒŒì¼ í•¸ë“¤ ë°©ë²• ì‹¤íŒ¨: {str(e3)[:200]}")
                    
                    # ë°©ë²• 4: pickle ì§ì ‘ ì‚¬ìš© (ìµœí›„ì˜ ìˆ˜ë‹¨)
                    try:
                        print(f"[AI] ë¡œë“œ ì‹œë„: pickle ì§ì ‘ ì‚¬ìš©")
                        import pickle
                        with open(model_path, 'rb') as f:
                            # PyTorchì˜ íŠ¹ìˆ˜ í¬ë§· ì²˜ë¦¬
                            unpickler = pickle.Unpickler(f)
                            unpickler.persistent_load = lambda pid: None  # persistent ID ë¬´ì‹œ
                            checkpoint = unpickler.load()
                        print(f"[AI] âœ… pickle ì§ì ‘ ì‚¬ìš©ìœ¼ë¡œ ë¡œë“œ ì„±ê³µ!")
                    except Exception as e4:
                        last_error = e4
                        print(f"[AI] âš ï¸  pickle ì§ì ‘ ì‚¬ìš© ì‹¤íŒ¨: {str(e4)[:200]}")
                        
                        # ë°©ë²• 5: íŒŒì¼ ë³µì‚¬ í›„ ì¬ì‹œë„ (ì†ìƒëœ íŒŒì¼ ë³µêµ¬ ì‹œë„)
                        try:
                            print(f"[AI] ë¡œë“œ ì‹œë„: ì„ì‹œ íŒŒì¼ë¡œ ë³µì‚¬ í›„ ì¬ì‹œë„")
                            import shutil
                            import tempfile
                            with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:
                                tmp_path = tmp_file.name
                                shutil.copy2(model_path, tmp_path)
                                checkpoint = torch.load(tmp_path, map_location="cpu", weights_only=False)
                                os.unlink(tmp_path)
                            print(f"[AI] âœ… ì„ì‹œ íŒŒì¼ë¡œ ë¡œë“œ ì„±ê³µ!")
                        except Exception as e5:
                            last_error = e5
                            print(f"[AI] âš ï¸  ì„ì‹œ íŒŒì¼ ë°©ë²• ì‹¤íŒ¨: {str(e5)[:200]}")
        
        if checkpoint is None:
            print(f"[AI] âŒ ëª¨ë“  ë¡œë“œ ë°©ë²• ì‹¤íŒ¨")
            print(f"[AI] ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
            print(f"[AI] âš ï¸  ëª¨ë¸ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print(f"[AI]    í•´ê²° ë°©ë²•:")
            print(f"[AI]    1. ëª¨ë¸ íŒŒì¼ì„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ/ë³µì‚¬í•˜ì„¸ìš”")
            print(f"[AI]    2. íŒŒì¼ì´ ì™„ì „íˆ ì „ì†¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            print(f"[AI]    3. íŒŒì¼ í¬ê¸°ê°€ ì •ìƒì¸ì§€ í™•ì¸í•˜ì„¸ìš” (í˜„ì¬: {file_size / (1024*1024):.2f} MB)")
            import traceback
            traceback.print_exc()
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨í•´ë„ ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë˜ë„ë¡ False ë°˜í™˜
            return False

        # í´ë˜ìŠ¤ ë ˆì´ë¸” ì •ë³´ ì¶”ì¶œ
        if checkpoint.get("id2label"):
            num_classes = len(checkpoint["id2label"])
            id2label = checkpoint["id2label"]
        else:
            # num_classes ì •ë³´ í™•ì¸
            num_classes = checkpoint.get("num_classes", 4)  # ê¸°ë³¸ê°’ 4 (ë…¸íŠ¸ë¶ê³¼ ë™ì¼)
            # ê¸°ë³¸ ë ˆì´ë¸” ì´ë¦„ (LABEL_0, LABEL_1, ...)
            id2label = {i: f"LABEL_{i}" for i in range(num_classes)}
        
        # í•œê¸€ ë ˆì´ë¸” ë§¤í•‘ ì¶”ê°€ (ë…¸íŠ¸ë¶ ì°¸ê³ )
        # id2label_korean: í•œê¸€ ì´ë¦„ ë§¤í•‘
        id2label_korean = {
            0: "ê°ˆë¨",
            1: "ê· ì—´",
            2: "ë¶€í›„",
            3: "ì••ê´´/í„°ì§"
        }
        # num_classesê°€ 4ë³´ë‹¤ ì‘ìœ¼ë©´ í•´ë‹¹ í´ë˜ìŠ¤ë§Œ ë§¤í•‘
        id2label_korean = {k: v for k, v in id2label_korean.items() if k < num_classes}

        # ëª¨ë¸ ì´ˆê¸°í™”
        model = CustomDeta(num_labels=num_classes)

        # state_dict ë¡œë“œ
        if "model_state_dict" in checkpoint:
            state_dict = checkpoint["model_state_dict"]
            # float32ë¡œ ë³€í™˜
            for k, v in state_dict.items():
                if isinstance(v, torch.Tensor):
                    state_dict[k] = v.to(torch.float32)
            model.model.load_state_dict(state_dict, strict=False)
        else:
            print(f"[AI] âš ï¸  ì²´í¬í¬ì¸íŠ¸ì— 'model_state_dict' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ë¡œë“œ ì‹œë„...")
            # state_dictê°€ ì§ì ‘ ì €ì¥ëœ ê²½ìš°
            model.model.load_state_dict(checkpoint, strict=False)

        model.eval()

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í”„ë¡œì„¸ì„œ ë¡œë“œ
        processor = DetaImageProcessor.from_pretrained("jozhang97/deta-resnet-50")

        print(f"[AI] âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print(f"[AI]    í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ")
        print(f"[AI]    ë ˆì´ë¸”: {id2label}")
        print(f"[AI]    í•œê¸€ ë ˆì´ë¸”: {id2label_korean}")
        if 'epoch' in checkpoint:
            print(f"[AI]    Epoch: {checkpoint['epoch'] + 1}")
        if 'best_map' in checkpoint:
            print(f"[AI]    Best mAP: {checkpoint['best_map']:.4f}")
        return True

    except Exception as e:
        import traceback
        print(f"[AI] âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        model, processor, id2label, id2label_korean = None, None, None, None
        return False


def get_model():
    """í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ë°˜í™˜"""
    return model


def get_processor():
    """í˜„ì¬ ë¡œë“œëœ í”„ë¡œì„¸ì„œ ë°˜í™˜"""
    return processor


def get_id2label():
    """í˜„ì¬ ë¡œë“œëœ ë ˆì´ë¸” ë§µ ë°˜í™˜"""
    return id2label


def get_id2label_korean():
    """í˜„ì¬ ë¡œë“œëœ í•œê¸€ ë ˆì´ë¸” ë§µ ë°˜í™˜"""
    return id2label_korean


def is_model_loaded():
    """ëª¨ë¸ ë¡œë“œ ì—¬ë¶€ í™•ì¸"""
    return model is not None and processor is not None
